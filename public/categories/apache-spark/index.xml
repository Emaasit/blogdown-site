<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Spark on Daniel Emaasit</title>
    <link>/categories/apache-spark/</link>
    <description>Recent content in Apache Spark on Daniel Emaasit</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Daniel Emaasit</copyright>
    <lastBuildDate>Tue, 08 Dec 2015 17:24:26 +0000</lastBuildDate>
    
	<atom:link href="/categories/apache-spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using Apache SparkR to Power Shiny Applications: Part I</title>
      <link>/post/2015/12/08/using-apache-sparkr-to-power-shiny-applications-part-i/</link>
      <pubDate>Tue, 08 Dec 2015 17:24:26 +0000</pubDate>
      
      <guid>/post/2015/12/08/using-apache-sparkr-to-power-shiny-applications-part-i/</guid>
      <description>Introduction The objective of this blog post is demonstrate how to use Apache SparkR to power Shiny applications. I have been curious about what the use cases for a &amp;ldquo;Shiny-SparkR&amp;rdquo; application would be and how to develop and deploy such an app.
SparkR is an R package that provides a light-weight frontend to use Apache Spark from R. SparkR provides a distributed data frame implementation that supports operations like selection, filtering, aggregation etc.</description>
    </item>
    
    <item>
      <title>Launch Apache Spark on AWS EC2 and Initialize SparkR Using RStudio</title>
      <link>/post/2015/11/10/launch-apache-spark-on-aws-ec2-and-initialize-sparkr-using-rstudio/</link>
      <pubDate>Tue, 10 Nov 2015 09:41:40 +0000</pubDate>
      
      <guid>/post/2015/11/10/launch-apache-spark-on-aws-ec2-and-initialize-sparkr-using-rstudio/</guid>
      <description>Introduction
In this blog post, we shall learn how to launch a Spark stand alone cluster on Amazon Web Services (AWS) Elastic Compute Cloud (EC2) for analysis of Big Data. This is a continuation from our previous blog, which showed us how to download Apache Spark and start SparkR locally on windows OS and RStudio.
We shall use Spark 1.5.1 (released on October 02, 2015) which has a spark-ec2 script that is used to install stand alone Spark on AWS EC2.</description>
    </item>
    
    <item>
      <title>Installing and Starting SparkR Locally on Windows OS and RStudio</title>
      <link>/post/2015/07/26/installing-and-starting-sparkr-locally-on-windows-8-1-and-rstudio/</link>
      <pubDate>Sun, 26 Jul 2015 09:11:00 +0000</pubDate>
      
      <guid>/post/2015/07/26/installing-and-starting-sparkr-locally-on-windows-8-1-and-rstudio/</guid>
      <description>Introduction
With the recent release of Apache Spark 1.4.1 on July 15th, 2015, I wanted to write a step-by-step guide to help new users get up and running with SparkR locally on a Windows machine using command shell and RStudio. SparkR provides an R frontend to Apache Spark and using Spark’s distributed computation engine allows R-Users to run large scale data analysis from the R shell. The steps listed here WILL also be documented in my upcoming online book titled &amp;ldquo;Getting Started with SparkR for Big Data Analysis&amp;rdquo; which can be accessed at: http://www.</description>
    </item>
    
  </channel>
</rss>