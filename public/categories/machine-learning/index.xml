<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Daniel Emaasit</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Daniel Emaasit</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Daniel Emaasit</copyright>
    <lastBuildDate>Mon, 14 Aug 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/machine-learning/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>ICYMI: My talk on Introduction to Probabilistic Machine Learning</title>
      <link>/post/2017/08/14/introduction-to-probabilistic-machine-learning/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/08/14/introduction-to-probabilistic-machine-learning/</guid>
      <description>&lt;p&gt;Incase you missed it, here is a recording of my talk on Introduction to Probabilisitic Machine Learning at the Las Vegas R &amp;amp; Data Science Meetup groups.&lt;/p&gt;
&lt;p&gt;I introduced probabilistic machine learning and probabilistic programming with Stan. I discussed the basics of machine learning from a probabilistic/Bayesian perspective and contrasted it with traditional/algorithmic machine learning. I also discussed how to build probabilistic models in computer code using a new exciting programming paradigm called Probabilistic Programming (PP). Particularly I used Stan (within R), a PP language, to build models ranging from simple generalized linear models to complex hierarchical models and nonparametric models for machine learning.&lt;/p&gt;
&lt;p&gt;Slides and code can be found on Github &lt;a href=&#34;https://bit.ly/intro-pml-lv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;part-i&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part I&lt;/h2&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/ICFtztrK9a4&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;div id=&#34;part-ii&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part II&lt;/h2&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/YsGAce_3Ql4&#34; frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>In case you missed it: My Webinar on Model-Based Machine Learning</title>
      <link>/post/2016/08/03/in-case-you-missed-it-my-webinar-on-model-based-machine-learning/</link>
      <pubDate>Wed, 03 Aug 2016 07:41:44 +0000</pubDate>
      
      <guid>/post/2016/08/03/in-case-you-missed-it-my-webinar-on-model-based-machine-learning/</guid>
      <description>&lt;p&gt;In case you missed my free webinar on &amp;ldquo;&lt;strong&gt;&lt;a href=&#34;https://danielemaasit.com/post/2016/07/16/webinar-model-based-machine-learning-and-probabilistic-programming-using-rstan/&#34; target=&#34;_blank&#34;&gt;Model-Based Machine Learning&lt;/a&gt;&lt;/strong&gt;&amp;rdquo;,  here is the recording.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/175956118&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Apologies for the poor quality of the video. Domino Data Lab&amp;rsquo;s webinar platform suffered a service degradation while recording the event. The webinar slides may be found below.&lt;/p&gt;

&lt;p&gt;&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/joTxMMvOmslHWt&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/DanielEmaasit/introduction-to-modelbased-machine-learning&#34; title=&#34;Introduction to Model-Based Machine Learning&#34; target=&#34;_blank&#34;&gt;Introduction to Model-Based Machine Learning&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a target=&#34;_blank&#34; href=&#34;https://www.slideshare.net/DanielEmaasit&#34;&gt;Daniel Emaasit&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;&lt;/p&gt;

&lt;p&gt;If you have any questions, please do not hesitate to contact me. Finally, I would like to thank &lt;a href=&#34;https://www.linkedin.com/in/enthoven&#34; target=&#34;_blank&#34;&gt;Daniel Enthoven&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/danielchalef&#34; target=&#34;_blank&#34;&gt;Daniel Chalef&lt;/a&gt; from Domino Data Lab for setting up this webinar.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Webinar: Model-Based Machine Learning and Probabilistic Programming using RStan</title>
      <link>/post/2016/07/16/webinar-model-based-machine-learning-and-probabilistic-programming-using-rstan/</link>
      <pubDate>Sat, 16 Jul 2016 22:36:00 +0000</pubDate>
      
      <guid>/post/2016/07/16/webinar-model-based-machine-learning-and-probabilistic-programming-using-rstan/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://emaasit.files.wordpress.com/2016/07/mbml-webinar2.png&#34; alt=&#34;mbml-webinar2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I am glad to announce that I shall be presenting a live webinar with &lt;a href=&#34;https://www.dominodatalab.com/&#34; target=&#34;_blank&#34;&gt;Domino Data Labs&lt;/a&gt; on July 20, 2016 from 11:00 - 11:30 AM PST on &lt;a href=&#34;https://blog.dominodatalab.com/an-introduction-to-model-based-machine-learning/&#34; target=&#34;_blank&#34;&gt;Model-Based Machine Learning and Probabilistic Programming using RStan&lt;/a&gt;. If you are interested in adopting machine learning but are overwhelmed by the vast amount of learning algorithms, this webinar will show how to overcome that challenge. This &lt;a href=&#34;https://blog.dominodatalab.com/an-introduction-to-model-based-machine-learning/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; describes most of the material we will cover in the webinar. Here is the &lt;a href=&#34;https://www.dominodatalab.com/resource/webinar/model-based-machine-learning&#34; target=&#34;_blank&#34;&gt;abstract&lt;/a&gt; for the webinar:
&lt;!-- more --&gt;&lt;/p&gt;

&lt;blockquote&gt;

&gt; 
&gt; ## Synopsis
&gt; 
&gt; 

&gt; 
&gt; In the last several decades, thousands of machine learning algorithms have been developed. Very often, the selection of an algorithm to solve a particular problem is driven more by the data scientist&#39;s familiarity with a small subset of available algorithms, than optimizing for predictive power or operational constraints. This is unsurprising: Newcomers to machine learning and veteran data scientists alike, may be overwhelmed by the multitude of machine learning algorithms and where and how it is most appropriate to use them.
&gt; 
&gt; 

&gt; 
&gt; In this webinar, Daniel Emaasit will introduce Model-Based Machine Learning (MBML), an approach to machine learning which addresses these challenges. Daniel will discuss the various uses of MBML, from tasks such as classification, to regression and clustering, and how it allows data scientists to address the uncretainty inherent to real-world machine learning applications. Daniel will demonstrate how to implement MBML in a probabilistic programming language called Stan, using the RStan package. At the end of webinar, attendees will have the knowledge to build their own custom probabilistic models, learning their parameters from data.
&gt; 
&gt; 
![Daniel Emaasit](https://www.dominodatalab.com/images/resources/daniel-e.jpg)

&gt; 
&gt; ## About the Speaker
&gt; 
&gt; 
Daniel Emaasit is a Ph.D Student of Transportation Engineering at UNLV, where his research interests involve the development of probabilistic machine learning methods for high-dimensional data, with applications to urban mobility, transport planning, highway safety, &amp; traffic operations.&lt;/blockquote&gt;

&lt;p&gt;Click this &lt;a href=&#34;https://www.dominodatalab.com/resource/webinar/model-based-machine-learning&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt; to register for the webinar. I look forward to seeing you there and answering your questions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Incase you missed it: My Talk at the United Nations Global Pulse Workshop</title>
      <link>/post/2016/07/07/incase-you-missed-it-my-talk-at-the-united-nations-global-pulse-worshop/</link>
      <pubDate>Thu, 07 Jul 2016 23:16:47 +0000</pubDate>
      
      <guid>/post/2016/07/07/incase-you-missed-it-my-talk-at-the-united-nations-global-pulse-worshop/</guid>
      <description>&lt;p&gt;In case you missed my talk at the &lt;a href=&#34;http://www.datascienceafrica.org/dsa2016/#workshop&#34; target=&#34;_blank&#34;&gt;2016 Data Science Africa Workshop&lt;/a&gt; organized by the &lt;a href=&#34;http://unglobalpulse.org/kampala&#34; target=&#34;_blank&#34;&gt;United Nations Global Pulse Lab&lt;/a&gt;, here is the recording. My talk was titled &amp;ldquo;&lt;em&gt;&lt;a href=&#34;http://blog.danielemaasit.com/2016/06/28/a-preview-of-my-talk-for-the-data-science-africa-workshop-organized-by-the-united-nations/&#34; target=&#34;_blank&#34;&gt;Sustainable Urban Transport Planning using Big Data from Mobile Phones&lt;/a&gt;&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/47IjdD2yyGE&#34; target=&#34;_blank&#34;&gt;https://youtu.be/47IjdD2yyGE&lt;/a&gt;&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;You can download slides for my talk from &lt;a href=&#34;https://www.dropbox.com/s/v53ymxth8x4hpe1/dsa_2016_presentation.pdf?dl=0&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[slideshare id=63828079&amp;amp;doc=dsa2016presentation-160707230510]&lt;/p&gt;

&lt;p&gt;There were also talks from my colleagues at &lt;a href=&#34;http://www.research.ibm.com/labs/africa/&#34; target=&#34;_blank&#34;&gt;IBM Research - Africa&lt;/a&gt; including Oliver Bent, Simone Fobi and Skyler Speakman who gave a general overview of the work we are doing in our lab in Nairobi, Kenya. Here is their recording:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/gxFstDWf9VU&#34; target=&#34;_blank&#34;&gt;https://youtu.be/gxFstDWf9VU&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I would like to thank Dr. John Quinn and the entire team a the &lt;a href=&#34;http://unglobalpulse.org/kampala&#34; target=&#34;_blank&#34;&gt;UNGP - Kampala&lt;/a&gt; for the invitation to speak and for a well organized event.  You can read more about the workshop from this &lt;a href=&#34;http://unglobalpulse.org/news/data-science-in-africa-2016&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; at the &lt;a href=&#34;http://unglobalpulse.org/blog&#34; target=&#34;_blank&#34;&gt;UNGP blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was great meeting a lot of people from academia, industry, non-profits and government who are using Data Science to solve several challenges on the African continent, ranging from health care to agriculture and to sustainable cities. I look forward to attending more events in the future.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_510&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;525&amp;rdquo;]&lt;img src=&#34;https://emaasit.files.wordpress.com/2016/07/dsa-pic.jpg&#34; alt=&#34;dsa-pic&#34; /&gt; United Nations Global Pulse Lab Kampala and partners from academia, industry, non-profit, government came together for the second workshop on Data Science in Africa, which was organized between 27 June - 1 July in Kampala, Uganda[/caption]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Preview of My Talk for the Data Science Africa Workshop organized by the United Nations</title>
      <link>/post/2016/06/28/a-preview-of-my-talk-for-the-data-science-africa-workshop-organized-by-the-united-nations/</link>
      <pubDate>Tue, 28 Jun 2016 10:36:32 +0000</pubDate>
      
      <guid>/post/2016/06/28/a-preview-of-my-talk-for-the-data-science-africa-workshop-organized-by-the-united-nations/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://emaasit.files.wordpress.com/2016/06/un.png&#34; alt=&#34;un&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I am excited to be invited by the &lt;a href=&#34;http://www.unglobalpulse.org/kampala&#34; target=&#34;_blank&#34;&gt;United Nations Global Pulse lab&lt;/a&gt; to speak at the &lt;a href=&#34;http://www.datascienceafrica.org/dsa2016/#workshop&#34; target=&#34;_blank&#34;&gt;2nd Data Science Africa Workshop&lt;/a&gt; scheduled to take place in Kampala, Uganda from 30th June to 1st July. The theme of this workshop is &amp;ldquo;&lt;em&gt;Using data science to monitor and achieve the global goals (UNDP goals) in Africa&lt;/em&gt;&amp;rdquo;. I will be speaking particularly on &amp;ldquo;&lt;em&gt;Data Science for Sustainable Cities&amp;rdquo;&lt;/em&gt;. My talk is titled: &amp;ldquo;&lt;em&gt;Sustainable Urban Transport Planning using Big Data from Mobile Phones&lt;/em&gt;&amp;rdquo;; which is the work I am doing as part of my PhD research. Particularly, I will talk about how developing countries can leverage low-cost, readily available and massive amounts of mobile phone data to improve their Transportation Planning policies.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;img src=&#34;https://emaasit.files.wordpress.com/2016/06/congestion1.jpg&#34; alt=&#34;congestion1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the past decades, there has been rapid urbanization as more and more people migrate into cities. The World Health Organization (WHO) estimates that by 2017, a majority of people will be living in urban areas. By 2030, 5 billion people—60 percent of the world’s population—will live in cities, compared with 3.6 billion in 2013. Developing nations must cope with this rapid urbanization. Transportation and urban planners must estimate travel demand for transportation facilities and use this to plan transportation infrastructure. Presently, the technique used for transportation planning uses data inputs from local and national household travel surveys. However, these surveys are expensive to conduct, cover smaller areas of cities and the time between surveys range from 5 to 10 years. This calls for new and innovative ways for Transportation Planning using new data sources.&lt;/p&gt;

&lt;p&gt;In recent years, we have witnessed the proliferation of ubiquitous mobile computing devices in developing countries. These mobile phones capture the movement of vehicles and people in near real time and generate massive amounts of new data.  My PhD research investigates how we can utilize anonymized mobile phone data ( i.e. Call Detail Records) and probabilistic machine learning to infer travel/mobility patterns. One of the objectives of this research is to demonstrate that these new “big” data sources are cheaper alternatives for transport modeling and travel behavior studies.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll have various UN and government people doing urban planning who I think would enjoy this topic — see you there! .&lt;/p&gt;

&lt;p&gt;If you haven’t already, register for &lt;a href=&#34;http://goo.gl/forms/Et8ztKOQmo&#34; target=&#34;_blank&#34;&gt;Data Science Africa Workshop 2016 here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Apache SparkR to Power Shiny Applications: Part I</title>
      <link>/post/2015/12/08/using-apache-sparkr-to-power-shiny-applications-part-i/</link>
      <pubDate>Tue, 08 Dec 2015 17:24:26 +0000</pubDate>
      
      <guid>/post/2015/12/08/using-apache-sparkr-to-power-shiny-applications-part-i/</guid>
      <description>

&lt;p&gt;&lt;em&gt;This post was first published on &lt;a href=&#34;http://blog.sparkiq-labs.com&#34; target=&#34;_blank&#34;&gt;SparkIQ Labs&amp;rsquo; blog&lt;/a&gt; and re-posted on my personal blog.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;shiny-sparkr-https-sparkiqlabs-files-wordpress-com-2015-11-shiny-sparkr-jpg-w-300-https-sparkiqlabs-files-wordpress-com-2015-11-shiny-sparkr-jpg&#34;&gt;&lt;a href=&#34;https://sparkiqlabs.files.wordpress.com/2015/11/shiny-sparkr.jpg&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://sparkiqlabs.files.wordpress.com/2015/11/shiny-sparkr.jpg?w=300&#34; alt=&#34;shiny-sparkr&#34; /&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The objective of this blog post is demonstrate how to use &lt;a href=&#34;http://spark.apache.org&#34; target=&#34;_blank&#34;&gt;Apache SparkR&lt;/a&gt; to power &lt;a href=&#34;http://shiny.rstudio.com&#34; target=&#34;_blank&#34;&gt;Shiny applications&lt;/a&gt;. I have been curious about what the use cases for a &amp;ldquo;Shiny-SparkR&amp;rdquo; application would be and how to develop and deploy such an app.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SparkR&lt;/strong&gt; is an R package that provides a light-weight frontend to use Apache Spark from R. SparkR provides a distributed data frame implementation that supports operations like selection, filtering, aggregation etc. (similar to R data frames, dplyr) but on large datasets. SparkR also supports distributed machine learning using MLlib.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shiny&lt;/strong&gt; is an open source R package that provides an elegant and powerful web framework for building web applications using R. Shiny helps you turn your analyses into interactive web applications without requiring HTML, CSS, or JavaScript knowledge.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3 id=&#34;use-cases&#34;&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;So you&amp;rsquo;re probably asking yourself, &amp;ldquo;Why would I need to use SparkR to run my Shiny applications?&amp;rdquo;. That is a legitimate question and to answer it, we need to understand the different classes of big data problems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Classes of Big Data Problems&lt;/strong&gt;
In a recent &lt;a href=&#34;http://bit.ly/1LbWPhl&#34; target=&#34;_blank&#34;&gt;AMA on Reddit&lt;/a&gt;, &lt;a href=&#34;http://had.co.nz/&#34; target=&#34;_blank&#34;&gt;Hadley Wickham&lt;/a&gt; (Chief Scientist at &lt;a href=&#34;https://www.rstudio.com/&#34; target=&#34;_blank&#34;&gt;RStudio&lt;/a&gt;) painted a clearer picture of how &amp;ldquo;Big Data&amp;rdquo; should be defined. His insights will help us to define uses cases for SparkR and Shiny.&lt;/p&gt;

&lt;p&gt;I believe big data problems should be categorized in 3 main classes:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Big Data-Small Analytics:&lt;/strong&gt; This is where a data scientist begins with a raw big dataset and then slices and dices that data to obtain the right sample required to answer a specific business/research problem. In most cases the resulting sample is a small dataset, which &lt;strong&gt;doesnot&lt;/strong&gt; require the use of SparkR to run a shiny application.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Partition Aggregrate Analytics:&lt;/strong&gt; This is where a data scientist needs to distribute and parallelize computation over multiple machines. Wickham defines this problem as a &lt;strong&gt;trivially parallelisable problem&lt;/strong&gt;. An example is when you need to fit one model per individual for thousands of individuals. In this case SparkR is a good fit but there are also packages in R that solve this problem such as the &lt;a href=&#34;https://cran.r-project.org/web/packages/foreach/index.html&#34; target=&#34;_blank&#34;&gt;foreach package&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Big Data-Large Scale Analytics&lt;/strong&gt;. This is where a data scientist needs all the big data, perhaps because they are fitting a complex model. An example of this type of problem is recommender systems which really do benefit from lots of data because they need to recognize interactions that occur only rarely. SparkR is a perfect fit for this problem when developing Shiny applications.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Memory Considerations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Also, it&amp;rsquo;s important to take into consideration memory availability and size when looking into such an application. This can be viewed in two different ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you are running your shiny applications on servers that have more than enough memory to fit your big data, then you probrably do not need SparkR. Nowadays there is accessibility to machines with terabytes on RAM from cloud providers like &lt;a href=&#34;http://aws.amazon.com&#34; target=&#34;_blank&#34;&gt;Amazon AWS&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If your big data cannot fit on one machine, you may need to distribute it on several machines. SparkR is a perfect fit for this problem because it provides distributed algorithms that can crunch your data on different worker nodes and return the result to the master node.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;a-simple-illustrative-example&#34;&gt;&lt;strong&gt;A Simple Illustrative Example&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Before we start understanding how each piece of such an application would operate, let&amp;rsquo;s download and run this simple Shiny-SparkR application. Go to this github repository &lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos&#34; target=&#34;_blank&#34;&gt;https://github.com/SparkIQ-Labs/Demos&lt;/a&gt; and access the &lt;strong&gt;&amp;ldquo;shiny-sparkr-demo-1&amp;rdquo;&lt;/strong&gt; example.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/repo.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/repo.png&#34; alt=&#34;Repository&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Make sure you already have Apache Spark 1.5 or later downloaded onto your computer. Instructions for downloading and starting SparkR can be found in this &lt;a href=&#34;http://bit.ly/1kP5Fbm&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Make sure you have Java 1.7.x installed and the environment variables are set.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;launch-the-app&#34;&gt;&lt;strong&gt;Launch the App&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Once you have downloaded the app-folder, open the project in RStudio and open the &lt;strong&gt;&amp;ldquo;server.R&amp;rdquo;&lt;/strong&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. **Change Spark Home**. Change the path of the **SPARK_HOME** environment variable to point to the destination of your Spark installation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/spark-home.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/spark-home.png&#34; alt=&#34;Change Spark home&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Run the App&lt;/strong&gt;. Run the shiny app by using this command &lt;code&gt;shiny::runApp()&lt;/code&gt;. It will take some time for SparkR to be initialized before you can see the results of the underlying analysis are displayed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/app.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/app.png&#34; alt=&#34;The App&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is the the code for the &amp;ldquo;server.R&amp;rdquo; file.&lt;/p&gt;

&lt;p&gt;[gist]7cf8aa8efc535db160df[/gist]&lt;/p&gt;

&lt;h3 id=&#34;what-happens-underneath&#34;&gt;&lt;strong&gt; What happens Underneath.&lt;/strong&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;1. **Stage 1:** When you run the app, the user interface is displayed but without the rendered text output or model summary.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/no-results.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/no-results.png&#34; alt=&#34;App without the results&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. **Stage 2:** Meanwhile, in the background on your computer node(s), java is launched using the Spark-submit file, then the SparkR library is loaded and then SparkR is initialized.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/java-launch.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/java-launch.png&#34; alt=&#34;SparkR is initialized&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. **Stage 3:** SparkR commands in the Server.R file are then executed, which finally shows the output within the shiny app.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/app.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/app.png&#34; alt=&#34;Results in the App&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can use the Spark UI to check the jobs that were completed, in the event timeline, to produce the final results in the shiny app. Go to localhost and listen on port 4040.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/event-timeline.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/event-timeline.png&#34; alt=&#34;Results in the App&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stage 4:&lt;/strong&gt; When you change the input values in the app and click the &amp;ldquo;Predict Sepal Length&amp;rdquo; button, the application uses the already exciting Spark Context to run the predict function and displays the predicted value. This operations takes a shorter time than the initial launch of the shiny app.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/SparkIQ-Labs/Demos/blob/master/shiny-sparkr-demo-1/img/new-result.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/SparkIQ-Labs/Demos/raw/master/shiny-sparkr-demo-1/img/new-result.png&#34; alt=&#34;Change values&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;moving-forward&#34;&gt;&lt;strong&gt;Moving Forward&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The objective of this first demo was to learn the use cases for SparkR and Shiny; and to see what happens underneath when you eventually deploy and run such an application on a PC.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;Part II&lt;/strong&gt; of this tutorial series, we shall see how to develop and deploy such an application for a &amp;ldquo;Big Data-Large Scale Analytics&amp;rdquo; problem on big data stored on a cluster on AWS EC2. As we have already established this is one of the perfect use cases for SparkR and Shiny.&lt;/p&gt;

&lt;p&gt;Please share your thoughts and experiences in the comments&amp;rsquo; section below if you have built such applications.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
